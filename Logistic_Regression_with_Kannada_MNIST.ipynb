{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Logistic Regression with Kannada-MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPfNqKIfWJuhOlRgzPko++J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kgrisk/Kaggle_Notebooks/blob/master/Logistic_Regression_with_Kannada_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ad_9x51kRdZJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c7d1b901-846c-44a6-8317-93ecacbebb8f"
      },
      "source": [
        "!pip install fastai2\n",
        "!pip install panda"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fastai2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/26/4f/0f61bb0d376eb47c20430639bac4946ca0cffcd7e693fb86698656324f2d/fastai2-0.0.17-py3-none-any.whl (190kB)\n",
            "\r\u001b[K     |█▊                              | 10kB 16.2MB/s eta 0:00:01\r\u001b[K     |███▌                            | 20kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 30kB 4.6MB/s eta 0:00:01\r\u001b[K     |███████                         | 40kB 5.1MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 51kB 5.0MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 61kB 5.5MB/s eta 0:00:01\r\u001b[K     |████████████                    | 71kB 6.1MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 81kB 6.4MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 92kB 6.2MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 102kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 112kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 122kB 6.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 133kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 143kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 153kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 163kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 174kB 6.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 184kB 6.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 194kB 6.5MB/s \n",
            "\u001b[?25hCollecting fastcore\n",
            "  Downloading https://files.pythonhosted.org/packages/e2/6e/a18c0ff6cdca36915e65cf1690137134241a33d74ceef7882f4a63a6af55/fastcore-0.1.18-py3-none-any.whl\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from fastai2) (3.13)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from fastai2) (7.0.0)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.6/dist-packages (from fastai2) (0.6.1+cu101)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai2) (1.0.5)\n",
            "Requirement already satisfied: fastprogress>=0.1.22 in /usr/local/lib/python3.6/dist-packages (from fastai2) (0.2.3)\n",
            "Requirement already satisfied: torch>=1.3.0 in /usr/local/lib/python3.6/dist-packages (from fastai2) (1.5.1+cu101)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from fastai2) (0.22.2.post1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.6/dist-packages (from fastai2) (2.2.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai2) (3.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai2) (1.4.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from fastai2) (2.23.0)\n",
            "Requirement already satisfied: dataclasses>='0.7'; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastcore->fastai2) (1.18.5)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->fastai2) (2.8.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.3.0->fastai2) (0.16.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->fastai2) (0.15.1)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (1.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (2.0.3)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (4.41.1)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (47.3.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (1.0.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (1.1.3)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (3.0.2)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy->fastai2) (0.4.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai2) (1.2.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2) (2020.4.5.2)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->fastai2) (3.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas->fastai2) (1.12.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy->fastai2) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy->fastai2) (3.1.0)\n",
            "Installing collected packages: fastcore, fastai2\n",
            "Successfully installed fastai2-0.0.17 fastcore-0.1.18\n",
            "Collecting panda\n",
            "  Downloading https://files.pythonhosted.org/packages/79/03/74996420528fe488ce17c42b6400531c8067d7eb661c304fa3aa8fdad17c/panda-0.3.1.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from panda) (47.3.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from panda) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->panda) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->panda) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->panda) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->panda) (2020.4.5.2)\n",
            "Building wheels for collected packages: panda\n",
            "  Building wheel for panda (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for panda: filename=panda-0.3.1-cp36-none-any.whl size=7260 sha256=8c94fd1e6ab229208bcc5e0c4ebd5235eec6759fae288f948aea3f5b1feb86e9\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/c8/45/06ed898b0bb401c1ff207dbb05b1587ff28860a236d98b1996\n",
            "Successfully built panda\n",
            "Installing collected packages: panda\n",
            "Successfully installed panda-0.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhYtiJSMfrn1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import graphviz\n",
        "def gv(s): return graphviz.Source('digraph G{ rankdir=\"LR\"' + s + '; }')"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOywbaB0eGgM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "#Simple neural network with Kannada-MNIST\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaeyhyLAg4HQ",
        "colab_type": "text"
      },
      "source": [
        "Hello,\n",
        " In this blog, I am going to implement a simple linear model using logistic regression and will extend it to the simple neural network. This will mainly be based on fastai books, chapter 4, remaking it with Kannada-MNIST. This blog won't include any visual explanations on how neural networks works and will be focused on the explanation of the written code.\n",
        "So let us start!\n",
        "Whether you are making a neural network, you usually follow these 7 steps.\n",
        "1.  Initialize the weights.\n",
        "2.  For each image, make a forward pass through your network using the values of the weights to calculate the predictions.\n",
        "3.  Compare the predictions with actual values and calculate the loss.\n",
        "4.  Backpropagate the loss through your network. This will calculate the gradient for each of your parameters.\n",
        "5.  Subtract part of the gradients from each of your parameters, that way making them closer to the values that you need to make accurate predictions.\n",
        "6.  Go back to step 2 and repeat the process.\n",
        "7.  Repeat the process until you decided that the model is good enough, or you can no longer improve.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JYtX8zo3fTfG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "3538fa54-2074-49eb-844d-aa4804ac51ff"
      },
      "source": [
        "gv('''\n",
        "init->predict->loss->gradient->step->stop\n",
        "step->predict[label=repeat]\n",
        "''')"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.files.Source at 0x7ff905d3bf60>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: G Pages: 1 -->\n<svg width=\"597pt\" height=\"78pt\"\n viewBox=\"0.00 0.00 596.69 78.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 74)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-74 592.6863,-74 592.6863,4 -4,4\"/>\n<!-- init -->\n<g id=\"node1\" class=\"node\">\n<title>init</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"27\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">init</text>\n</g>\n<!-- predict -->\n<g id=\"node2\" class=\"node\">\n<title>predict</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"127.3968\" cy=\"-18\" rx=\"36.2938\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"127.3968\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">predict</text>\n</g>\n<!-- init&#45;&gt;predict -->\n<g id=\"edge1\" class=\"edge\">\n<title>init&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M54.1688,-18C62.3543,-18 71.5827,-18 80.6596,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"80.7795,-21.5001 90.7795,-18 80.7795,-14.5001 80.7795,-21.5001\"/>\n</g>\n<!-- loss -->\n<g id=\"node3\" class=\"node\">\n<title>loss</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"227.7935\" cy=\"-52\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"227.7935\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">loss</text>\n</g>\n<!-- predict&#45;&gt;loss -->\n<g id=\"edge2\" class=\"edge\">\n<title>predict&#45;&gt;loss</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M157.5191,-28.2011C168.9806,-32.0826 182.1139,-36.5303 193.9014,-40.5222\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"192.8259,-43.8532 203.4202,-43.7458 195.0713,-37.2231 192.8259,-43.8532\"/>\n</g>\n<!-- gradient -->\n<g id=\"node4\" class=\"node\">\n<title>gradient</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"365.7399\" cy=\"-52\" rx=\"40.8928\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"365.7399\" y=\"-48.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">gradient</text>\n</g>\n<!-- loss&#45;&gt;gradient -->\n<g id=\"edge3\" class=\"edge\">\n<title>loss&#45;&gt;gradient</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M255.0473,-52C272.0415,-52 294.4481,-52 314.6545,-52\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"314.671,-55.5001 324.671,-52 314.671,-48.5001 314.671,-55.5001\"/>\n</g>\n<!-- step -->\n<g id=\"node5\" class=\"node\">\n<title>step</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"470.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"470.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">step</text>\n</g>\n<!-- gradient&#45;&gt;step -->\n<g id=\"edge4\" class=\"edge\">\n<title>gradient&#45;&gt;step</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M398.9456,-41.2422C410.9558,-37.3512 424.5297,-32.9536 436.6132,-29.0388\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"437.9112,-32.2975 446.3457,-25.8857 435.7537,-25.6382 437.9112,-32.2975\"/>\n</g>\n<!-- step&#45;&gt;predict -->\n<g id=\"edge6\" class=\"edge\">\n<title>step&#45;&gt;predict</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M443.4266,-18C384.9297,-18 246.7861,-18 174.0495,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"173.8098,-14.5001 163.8098,-18 173.8097,-21.5001 173.8098,-14.5001\"/>\n<text text-anchor=\"middle\" x=\"289.7935\" y=\"-21.8\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">repeat</text>\n</g>\n<!-- stop -->\n<g id=\"node6\" class=\"node\">\n<title>stop</title>\n<ellipse fill=\"none\" stroke=\"#000000\" cx=\"561.6863\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"561.6863\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#000000\">stop</text>\n</g>\n<!-- step&#45;&gt;stop -->\n<g id=\"edge5\" class=\"edge\">\n<title>step&#45;&gt;stop</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M497.9893,-18C506.2676,-18 515.508,-18 524.3268,-18\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"524.4026,-21.5001 534.4025,-18 524.4025,-14.5001 524.4026,-21.5001\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLHl2sVOD7vV",
        "colab_type": "text"
      },
      "source": [
        "#Simple Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sdr1KTsJYeoN",
        "colab_type": "text"
      },
      "source": [
        "So now we can start doing our implementation. First, we will need to import the libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6sPvonoznfrq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "from fastai2.vision.all import *\n",
        "matplotlib.rc('image', cmap='Greys')"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwzoM3YIAMh7",
        "colab_type": "text"
      },
      "source": [
        "Then you need to go to the Kaggle website,  download the Kannada-MNIST dataset and unzip it. In the Kannada-MNIST case, we have four files zipped in it.\n",
        "For this implementation, I am going to be using only 'train.csv'."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0ajmfBulpnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "9bde0dca-3cfb-4a40-84b5-0b2a5e025ea3"
      },
      "source": [
        "!chmod 777 Kannada-MNIST.zip\n",
        "!unzip Kannada-MNIST.zip"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  Kannada-MNIST.zip\n",
            "  inflating: Dig-MNIST.csv           \n",
            "  inflating: sample_submission.csv   \n",
            "  inflating: test.csv                \n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xfiMaduAXPT",
        "colab_type": "text"
      },
      "source": [
        "The easy way of how you can read the 'train.csv' file is to use pandas function 'read_csv()'. It will read it into pandas DataFrame.\n",
        "By calling 'head()' on it, we can display the first five rows of its content.\n",
        "The first column of it is 'label'. It defines what category the row belongs to. \n",
        "Each of the other columns represents the pixels from 0 to 784, which is a flattened 28,28 shaped single-channel image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxTvhVbxg3R7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "74cdbe2b-24c7-4536-b587-88b17f62d482"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\") \n",
        "df.head()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>pixel9</th>\n",
              "      <th>pixel10</th>\n",
              "      <th>pixel11</th>\n",
              "      <th>pixel12</th>\n",
              "      <th>pixel13</th>\n",
              "      <th>pixel14</th>\n",
              "      <th>pixel15</th>\n",
              "      <th>pixel16</th>\n",
              "      <th>pixel17</th>\n",
              "      <th>pixel18</th>\n",
              "      <th>pixel19</th>\n",
              "      <th>pixel20</th>\n",
              "      <th>pixel21</th>\n",
              "      <th>pixel22</th>\n",
              "      <th>pixel23</th>\n",
              "      <th>pixel24</th>\n",
              "      <th>pixel25</th>\n",
              "      <th>pixel26</th>\n",
              "      <th>pixel27</th>\n",
              "      <th>pixel28</th>\n",
              "      <th>pixel29</th>\n",
              "      <th>pixel30</th>\n",
              "      <th>pixel31</th>\n",
              "      <th>pixel32</th>\n",
              "      <th>pixel33</th>\n",
              "      <th>pixel34</th>\n",
              "      <th>pixel35</th>\n",
              "      <th>pixel36</th>\n",
              "      <th>pixel37</th>\n",
              "      <th>pixel38</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel744</th>\n",
              "      <th>pixel745</th>\n",
              "      <th>pixel746</th>\n",
              "      <th>pixel747</th>\n",
              "      <th>pixel748</th>\n",
              "      <th>pixel749</th>\n",
              "      <th>pixel750</th>\n",
              "      <th>pixel751</th>\n",
              "      <th>pixel752</th>\n",
              "      <th>pixel753</th>\n",
              "      <th>pixel754</th>\n",
              "      <th>pixel755</th>\n",
              "      <th>pixel756</th>\n",
              "      <th>pixel757</th>\n",
              "      <th>pixel758</th>\n",
              "      <th>pixel759</th>\n",
              "      <th>pixel760</th>\n",
              "      <th>pixel761</th>\n",
              "      <th>pixel762</th>\n",
              "      <th>pixel763</th>\n",
              "      <th>pixel764</th>\n",
              "      <th>pixel765</th>\n",
              "      <th>pixel766</th>\n",
              "      <th>pixel767</th>\n",
              "      <th>pixel768</th>\n",
              "      <th>pixel769</th>\n",
              "      <th>pixel770</th>\n",
              "      <th>pixel771</th>\n",
              "      <th>pixel772</th>\n",
              "      <th>pixel773</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  ...  pixel780  pixel781  pixel782  pixel783\n",
              "0      0       0       0       0  ...         0         0         0         0\n",
              "1      1       0       0       0  ...         0         0         0         0\n",
              "2      2       0       0       0  ...         0         0         0         0\n",
              "3      3       0       0       0  ...         0         0         0         0\n",
              "4      4       0       0       0  ...         0         0         0         0\n",
              "\n",
              "[5 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2DJqNuuUhV3u",
        "colab_type": "text"
      },
      "source": [
        "Then we need to specify a number for random seed. Doing this will let us get the same generated parameters each time we run this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o6dV5ElU0CDo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "26e23495-4a59-43f1-9208-0bbc46b3bb25"
      },
      "source": [
        "torch.manual_seed(3)\n"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7ff9283f8a30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dASZD6dLh9D0",
        "colab_type": "text"
      },
      "source": [
        "Here we are converting our data into tuple format (x,y). This is required for PyTorch dataset.\n",
        "First, we separate the label from all other data into a separate tensor. Then we convert our other data(pixels) into tensor and normalize it by dividing it from 255. this converts our data to be in values between 0 and 1. Finally, we turn it into the tuple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYBD89a0L09V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_y = tensor(df['label'])\n",
        "df_x = tensor(df.drop('label', axis=1).values).float() / 255.\n",
        "df = list(zip(df_x,df_y))"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQnPOERRgvFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7059559e-b109-42d4-ee5f-2f1308763ca6"
      },
      "source": [
        "df_y.shape"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 134
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yKHtxDNSd-r7",
        "colab_type": "text"
      },
      "source": [
        "Then we split our data into training and validation sets using 'random_split(data, [split_one, split_two)' function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fwhw8WDgnoX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "38452e2e-e48f-4566-ab13-5792caf5c6e6"
      },
      "source": [
        "val_size = int(0.2*len(df))\n",
        "train_size = len(df) - val_size\n",
        "train_ds, val_ds = torch.utils.data.random_split(df, [train_size, val_size])\n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48000, 12000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 135
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kyPvpzIYfOWZ",
        "colab_type": "text"
      },
      "source": [
        "Now we can start our training process. First, we are going to make a parameter initialization function. It is going to take the wanted matrix shape and deviation range as an input and will return us the initialized matrix. We also call the 'requires_grad_()' function. This tells PyTorch that the created tensor will require gradients."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbY_ZuMc-fxg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_()"
      ],
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vjxpjr-gfqhJ",
        "colab_type": "text"
      },
      "source": [
        "We are going to have two types of parameters. First is going to be the weights. In this case, you can imagine weights as being values associated with the input. For every pixel in our image(784), we are going to have ten weights, which are going to indicate that pixels importance to each different prediction. All weights will be inside one big matrix representing our one linear layer weights.\n",
        "The second parameter is going to be bias, 1 per prediction, making it 10 in total."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plN6voH7-f32",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = init_params((28*28,10))\n",
        "bias = init_params(10)"
      ],
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8x2FLP_jdaq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1f46c821-c7ff-42c1-c8a3-67d42a8de851"
      },
      "source": [
        "df_x[0].shape, weights.shape, bias.shape"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), torch.Size([784, 10]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KK3R-7jVjLmK",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Let us try making a prediction for one image example. For each neuron, we need to multiply each pixel with its weight and sum all of the got values. Then we can add bias.\n",
        "This gives us one problem. The shape of our pixel tensor is [784], while the shape of our weights is [784, 10]. By transposing our weights matrix, we can get the shape [10,784]. This lets us do element-wise multiplication between two matrices. Python will consider the pixel matrix as being [1,784], and it will broadcast it across all of our weights matrix, giving us a new matrix of shape [10,784]."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfOTxDRrzWdi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eca01d50-15cd-495d-8b01-25ef16f8a984"
      },
      "source": [
        "weights[0]"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1771, -0.6914, -2.0339, -0.0146, -0.0184,  0.0774,  0.1353,  0.0976,\n",
              "         1.2196,  0.5419], grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6soiMxYP0pXX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b9886b8-f1bf-47ec-f9e0-84225bcfe7bd"
      },
      "source": [
        "(df_x[0]*weights.T).shape"
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7y31xnu05tN",
        "colab_type": "text"
      },
      "source": [
        "Then we can sum all values for each prediction and apply bias."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOZr4v3t-f6g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b1df2002-4769-4611-d776-5b6c346be449"
      },
      "source": [
        "(df_x[0]*weights.T).sum() + bias"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([7.9136, 6.4585, 8.1807, 6.9579, 6.9197, 7.2522, 7.6322, 5.7487, 8.0225,\n",
              "        6.9266], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 142
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8jnOVDvxo_cK",
        "colab_type": "text"
      },
      "source": [
        "Now let's try to make predictions for multiple examples. We could do it as before one image at the time, but python has a nice feature that lets us do matrix multiplication. You need to do everything just like before, but instead of '*' for multiplication, you have to use '@', and we no longer need to Transpose our weights tensor."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsFsoY60-f8_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "648f75be-3d54-4714-9af4-f67dc5be55be"
      },
      "source": [
        "def linear(xb): return xb@weights + bias\n",
        "preds = linear(df_x[:40])\n",
        "#five predictions\n",
        "preds[:5]"
      ],
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.8791,  2.8753, -1.8936,  8.4709,  0.4792, -8.4212, 13.1066,  4.8924,\n",
              "         -7.4439, -3.3860],\n",
              "        [ 1.8609, -7.1370,  5.0990,  2.7264, -2.2692, -3.1977,  1.4100,  0.6469,\n",
              "         -7.1241, -4.8157],\n",
              "        [ 5.4444,  5.1601,  3.0672, -6.4859, 11.8515, 14.0330,  4.9745,  0.2390,\n",
              "          1.2314, -1.5407],\n",
              "        [-1.0287,  3.9156,  6.9652,  4.6794, -1.9739,  4.1155,  2.4142, -1.3916,\n",
              "         -4.6344, -1.1138],\n",
              "        [ 3.6376,  6.2520,  4.0436,  0.5839, -1.3109, -1.8403,  2.0207,  4.5624,\n",
              "          5.1338,  4.0897]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMk_KqC1WWBL",
        "colab_type": "text"
      },
      "source": [
        "Now, when we have our predictions, we can try calculating the accuracy. We are going to take prediction tensor and will find the highest value for each image prediction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VM16bg_hXQB8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1c3d79a2-f628-4ab6-e062-d32d001295c4"
      },
      "source": [
        "_, example = torch.max(preds, dim=1)\n",
        "example"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([6, 2, 5, 2, 1, 3, 2, 0, 3, 6, 6, 6, 3, 1, 6, 3, 2, 6, 6, 3, 6, 6, 4, 6,\n",
              "        5, 3, 2, 7, 3, 7, 6, 6, 6, 6, 6, 6, 6, 0, 6, 7])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 144
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kes5t7SYX_nR",
        "colab_type": "text"
      },
      "source": [
        "Then we can take the predicted values and compare it with labels using '==' operation. This will give us a boolean matrix with 'True' in place of correct predictions and 'False' otherwise. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOX4hEoAYVjb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "36036ca6-beda-4746-a02e-357d6d3aa260"
      },
      "source": [
        "example == df_y[:40]"
      ],
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False, False, False, False,\n",
              "        False, False, False, False, False, False, False,  True, False, False,\n",
              "        False, False, False, False, False, False,  True, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aMow1yaJYuBZ",
        "colab_type": "text"
      },
      "source": [
        "By using torch 'sum()' function on it, we can get the total count of 'True' values, and by calling 'item()', we can access it as an integer value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OO7DU2hOYPwJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8800c29e-2d1b-4c63-9403-49c57cb4ab8c"
      },
      "source": [
        "torch.sum(example == df_y[:40]).item()"
      ],
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GckSd89yZLNh",
        "colab_type": "text"
      },
      "source": [
        "Then we have to divide it by total count of predictions getting the average of correct predictions value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f6EaLK1KXwUi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b989ed88-0ffd-45b3-d7b7-87dacb5188cf"
      },
      "source": [
        "torch.tensor(torch.sum(example == df_y[:40]).item() / len(example))"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWSUIV25XtOa",
        "colab_type": "text"
      },
      "source": [
        "Lets put everything into one function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwJYzO5v-gFZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mL-vPLTJ8KCz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf2c7e16-019a-459f-82a3-65e8e666a056"
      },
      "source": [
        "accuracy(preds, df_y[:40])"
      ],
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o4ewdUVZZbHS",
        "colab_type": "text"
      },
      "source": [
        "So as we can see, the prediction was terrible. What we want to do is improve our parameters and try calculating again. But how can we do that?\n",
        "We need to calculate our loss. The accuracy is not a way to calculate it. The reason for that is because accuracy gives us a value that is either right or wrong. We have no idea how wrong or right our prediction was. One way to calculate our loss is to convert our predictions into percentage values representing how likely this output to be the right prediction. So that all of our predictions together would be equal to 1.Thats that we call 'softmax'. By applying log on our calculated 'softmax' we get 'log_softmax' function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuoC5pIglD42",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def log_softmax(x): return x - x.exp().sum(-1).log().unsqueeze(-1)"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpP_o632vE8G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "eb4d183c-a31b-490d-a51c-e7033ae9fdbc"
      },
      "source": [
        "pred1 = log_softmax(preds)\n",
        "pred1[0]"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.1237e+01, -1.0241e+01, -1.5010e+01, -4.6457e+00, -1.2637e+01,\n",
              "        -2.1538e+01, -9.9735e-03, -8.2242e+00, -2.0560e+01, -1.6503e+01],\n",
              "       grad_fn=<SelectBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCYw9OLPiJYF",
        "colab_type": "text"
      },
      "source": [
        "Then we are going to select only the value of the correct predictions from all of the samples, calculate their average, and convert it to the positive value. This gives us 'Negative Log-Likelihood'. The bigger value of our output is, the bigger loss we have. The smaller value it is(close to zero), the smaller loss we get.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYsmww82Zu2d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def nll(input, target): return -input[range(target.shape[0]), target].mean()"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZybeHWj6Z6hk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0fc44f47-47ea-4b16-b93b-96e5acda5c2d"
      },
      "source": [
        "pred1 = log_softmax(preds)\n",
        "loss1 = nll(pred1, df_y[:40])\n",
        "loss1"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.5463, grad_fn=<NegBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "941zg_QpdUwf",
        "colab_type": "text"
      },
      "source": [
        "We don't need to implement those two functions by hand. We can use  PyTorch given 'cross_entropy' and get the same result as it is a combination of before implemented 'log_softmax' and 'negative_log_likehood' functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a809JC3KBl1Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2123ab43-67d9-4ef6-8337-7b08c13f4cc8"
      },
      "source": [
        "loss_fn = F.cross_entropy\n",
        "# Loss for current batch of data\n",
        "loss = loss_fn(preds, df_y[:40])\n",
        "print(loss)"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(9.5463, grad_fn=<NllLossBackward>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kqZSq6j6eGXm",
        "colab_type": "text"
      },
      "source": [
        "So now, then we have our loss its time to run our whole dataset and finally train our network. One thing that we are going to use for our full dataset is DataLoader. It is going to let us train our network using mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a554SzV0Gz9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dl = DataLoader(train_ds, batch_size=256)\n"
      ],
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4dtrNamlnca",
        "colab_type": "text"
      },
      "source": [
        "If we inspect the size of the first mini-batch, we will notice that it contains 256 images(same size as we defined before)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62vZDfrLc8LD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ede6bfd4-a4cf-4488-93b5-8f2d6fbe4ad3"
      },
      "source": [
        "xb,yb = first(dl)\n",
        "xb.shape,yb.shape"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 784]), torch.Size([256]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-R3KDZJlx5N",
        "colab_type": "text"
      },
      "source": [
        "Lets do the same for validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDNOTuGLFGLp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_dl = DataLoader(val_ds, batch_size=256)"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_4ylWtj8wIhQ",
        "colab_type": "text"
      },
      "source": [
        "Now to see if everything is going to work fine, first, let's try to train our network on small dataset example. Let's select 40 examples as before."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ImkxsXK6FaeP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "10a64203-0001-42e0-bc9b-97109e0daea0"
      },
      "source": [
        "batch = df_x[:40]\n",
        "batch.shape"
      ],
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([40, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2RU_MNGtwYvN",
        "colab_type": "text"
      },
      "source": [
        "Run it through the before made linear model and get our calculations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsRoZ4j5FahX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "db0aac9d-3472-480d-e55d-23da4906e7f1"
      },
      "source": [
        "preds = linear(batch)\n",
        "preds[:5]"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 1.8791,  2.8753, -1.8936,  8.4709,  0.4792, -8.4212, 13.1066,  4.8924,\n",
              "         -7.4439, -3.3860],\n",
              "        [ 1.8609, -7.1370,  5.0990,  2.7264, -2.2692, -3.1977,  1.4100,  0.6469,\n",
              "         -7.1241, -4.8157],\n",
              "        [ 5.4444,  5.1601,  3.0672, -6.4859, 11.8515, 14.0330,  4.9745,  0.2390,\n",
              "          1.2314, -1.5407],\n",
              "        [-1.0287,  3.9156,  6.9652,  4.6794, -1.9739,  4.1155,  2.4142, -1.3916,\n",
              "         -4.6344, -1.1138],\n",
              "        [ 3.6376,  6.2520,  4.0436,  0.5839, -1.3109, -1.8403,  2.0207,  4.5624,\n",
              "          5.1338,  4.0897]], grad_fn=<SliceBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-s30_wgZwkbW",
        "colab_type": "text"
      },
      "source": [
        "Calculate our losses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-NitINcFakk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9394e58f-c41a-4fdc-911a-720736d352e0"
      },
      "source": [
        "loss = loss_fn(preds, df_y[:40])\n",
        "loss"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(9.5463, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vnP3NfgfwtN-",
        "colab_type": "text"
      },
      "source": [
        "It seems that everything works just like before. Now we can start improving our score by optimizing our weights to give us better predictions. We will achieve this with backpropagation. With PyTorch, backpropagation is quite easy. If your parameters had 'requires_grad_()' function called(that we did), PyTorch knows that in case of backpropagation, these values need gradient calculated for them. So you only need to construct the forward pass of your network(what we already did) and call the 'backward()' function after calculating loss. It will make PyTorch calculate the gradients for all of the tensors with 'requires_grad_()' involved with the chain of calculations done calculating the loss."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PIJbt7HLFan4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "3b8f24c1-5e6f-42f5-b03f-3187bd22b0e2"
      },
      "source": [
        "loss.backward()\n",
        "weights.grad.shape,weights.grad.mean(),bias.grad"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 10]),\n",
              " tensor(-1.2164e-10),\n",
              " tensor([-0.0235, -0.0493,  0.0064,  0.0444, -0.0689, -0.0630,  0.3313,  0.0054,\n",
              "         -0.0891, -0.0937]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lz0JODFp099l",
        "colab_type": "text"
      },
      "source": [
        "Lets put everything into one function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ufH6BNJnFare",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calc_grad(xb, yb, model):\n",
        "    preds = model(xb)\n",
        "    loss = loss_fn(preds, yb)\n",
        "    loss.backward()"
      ],
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4RuDHviANiM4",
        "colab_type": "text"
      },
      "source": [
        "Call it again. As you can see while we done the same thing, our gradients increased twice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01yHEvyq796j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "1014c3f0-de4e-41b8-f22f-f7f92bc0c0a0"
      },
      "source": [
        "calc_grad(batch, df_y[:40], linear)\n",
        "weights.grad.mean(),bias.grad"
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(-2.4328e-10),\n",
              " tensor([-0.0471, -0.0987,  0.0127,  0.0889, -0.1379, -0.1260,  0.6627,  0.0108,\n",
              "         -0.1781, -0.1873]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uZOxoEIzvMW",
        "colab_type": "text"
      },
      "source": [
        "By calling 'backward()', we had our parameters gradients saved in 'grad' tensor. After we called 'backward()' again, our gradients had been stacked together with the previous iteration gradients. We want to calculate fresh gradients each time after we finish our training loop. So that we do is call 'zero_()' on our 'grad' tensor. This will do in-place cleaning of our parameter gradient. Note that any Python functions, which have '_' in their name, are usually doing in-place editing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MQvllQxjIEom",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights.grad.zero_()\n",
        "bias.grad.zero_();"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bkb3rAruOmwl",
        "colab_type": "text"
      },
      "source": [
        "So now, we mostly did everything that you need to train our neural network apart from updating the weights with the calculated gradient.\n",
        "\n",
        "Let's Initialize our parameters from the start and do everything in one function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QB42Cghwdav",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = init_params((28*28,10))\n",
        "bias = init_params(10)"
      ],
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbIW9UivO_6-",
        "colab_type": "text"
      },
      "source": [
        "'Train_epoch' basically contains our training loop. It runs our batches through a linear layer and calculates the loss and gradients. Finally, updates our parameters accordingly to it using the learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXuem1tmfokP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model, lr, params):\n",
        "    for xb,yb in dl:\n",
        "        calc_grad(xb, yb, model)\n",
        "        for p in params:\n",
        "            p.data -= p.grad*lr\n",
        "            p.grad.zero_()"
      ],
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp6kZOEWiGvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = .5\n",
        "params = weights,bias\n",
        "train_epoch(linear, lr, params)"
      ],
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e4_TbJ5tTNlX",
        "colab_type": "text"
      },
      "source": [
        "That's it! We just trained our linear layer for one epoch. Let's define our function for testing on the validation set. It will iterate through our mini-batches in the validation DataLoader, will calculate their accuracy using before defined 'accuracy' function. And will return us the average loss of our mini-batches."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBa6H4f7g0t4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def validate_epoch(model):\n",
        "    accs = [accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
        "    return round(torch.stack(accs).mean().item(), 6)"
      ],
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9cQ54kiqXVnt",
        "colab_type": "text"
      },
      "source": [
        "After 1 loop we got 83%. Thats not bad."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw61FwZohxaQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "09938d15-37bc-48a4-83d0-bfa8ca12bfad"
      },
      "source": [
        "validate_epoch(linear)"
      ],
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.838217"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 169
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6tEbOFoXmaM",
        "colab_type": "text"
      },
      "source": [
        "After iterating for another 20 times we have reached the accuracy of 95%. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOmHV2IbiRJX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "738e60a1-6d99-4c28-bc72-6688e5e613e0"
      },
      "source": [
        "for i in range(20):\n",
        "    train_epoch(linear, lr, params)\n",
        "    print(validate_epoch(linear), end=' ')"
      ],
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.882017 0.902106 0.913184 0.920272 0.925936 0.930044 0.933463 0.936455 0.938521 0.941098 0.94276 0.94409 0.945681 0.947343 0.948506 0.949254 0.949836 0.950917 0.951487 0.952401 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuNTlhbtl7fW",
        "colab_type": "text"
      },
      "source": [
        "Thats it! Thats the implementation of the logistic regression!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5lS8SsnrihXA",
        "colab_type": "text"
      },
      "source": [
        "#Creating an Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgXu2xyxlxyo",
        "colab_type": "text"
      },
      "source": [
        "Now, let's rewrite this in an easier way using PyTorch.\n",
        " \n",
        "First of all, PyTorch has a linear layer implementation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vW4OfYNXiY8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "linear_model = nn.Linear(28*28,10)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HkOCpTMOmZj3",
        "colab_type": "text"
      },
      "source": [
        "By using PyTorch layers, we no longer need to initialize parameters. PyTorch does it for us simply by looking at the specified shape for the required layer and creating parameters for it. By calling 'parameters()' function on our created layers, we can inspect the created parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4jb9OMamSsq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dd23f136-8a30-4c4c-fa29-c06c5e93d19e"
      },
      "source": [
        "w,b = linear_model.parameters()\n",
        "w.shape,b.shape"
      ],
      "execution_count": 172,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([10, 784]), torch.Size([10]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 172
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-5rmbFWnODH",
        "colab_type": "text"
      },
      "source": [
        "Let's define an optimizer class. That optimizer will do it will contain the functions for adjusting our parameters data after PyTorch calculates the gradients. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b6t7yNAm0GP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BasicOptim:\n",
        "    def __init__(self,params,lr): self.params,self.lr = list(params),lr\n",
        "\n",
        "    def step(self, *args, **kwargs):\n",
        "        for p in self.params: p.data -= p.grad.data * self.lr\n",
        "\n",
        "    def zero_grad(self, *args, **kwargs):\n",
        "        for p in self.params: p.grad = None"
      ],
      "execution_count": 173,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZtNl9KPYoK7",
        "colab_type": "text"
      },
      "source": [
        "To initialize it, you need to give it a parameters of your layer and a learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvJwxSF5m8Pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "opt = BasicOptim(linear_model.parameters(), lr)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qrt4xIrMYNV8",
        "colab_type": "text"
      },
      "source": [
        "As you can see, this is our updated training loop. It looks very much the same as the one we had before, with a difference that we have our parameters updating in a 'step()' function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxry_9R5nNBF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epoch(model):\n",
        "    for xb,yb in dl:\n",
        "        calc_grad(xb, yb, model)\n",
        "        opt.step()\n",
        "        opt.zero_grad()"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqY41m7M9D6y",
        "colab_type": "text"
      },
      "source": [
        "Initial value with no training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JulzOfxmng73",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc950cc4-2fbd-436b-9228-fdc79e6308e3"
      },
      "source": [
        "validate_epoch(linear_model)"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.966304"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3D_KMnoOnqxG",
        "colab_type": "text"
      },
      "source": [
        "Lets put Everything into one function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXfmUGugnpvv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, epochs):\n",
        "    for i in range(epochs):\n",
        "        train_epoch(model)\n",
        "        print(validate_epoch(model), end=' ')"
      ],
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ra6Wf6SkZyIm",
        "colab_type": "text"
      },
      "source": [
        "As you can see, we get very similar results as before. The only difference is that I have not reset the random seed before doing layer initialization, getting different random parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zIR5kwCnuYs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "51225d83-9e50-432e-d6a3-3b444be10cba"
      },
      "source": [
        "train_model(linear_model, 20)"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.950311 0.954906 0.957471 0.959477 0.960558 0.961472 0.961638 0.962054 0.962802 0.963395 0.963645 0.964143 0.964309 0.964725 0.965141 0.96539 0.965639 0.965972 0.966138 0.966304 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no2NZk0GoJ8f",
        "colab_type": "text"
      },
      "source": [
        "So now, let's make everything even more abstract. Before, we have created our optimizer class. Instead, we could have used PyTorch given SGD(Stochastic Gradient Descent) optimizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9FuEzXHfnw_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "20539d0f-f163-457d-cb71-534e9e3cc3ce"
      },
      "source": [
        "linear_model = nn.Linear(28*28,10)\n",
        "opt = SGD(linear_model.parameters(), lr)\n",
        "train_model(linear_model, 20)"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.948803 0.954134 0.957803 0.958812 0.960225 0.960724 0.961555 0.962149 0.96298 0.963395 0.963645 0.963977 0.964309 0.964642 0.965057 0.965224 0.965473 0.965722 0.966304 0.966637 "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xD2uV32DbShL",
        "colab_type": "text"
      },
      "source": [
        "We can make this even more abstract using fastai library. For fastai we need to use DataLoaders."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2TtSLKIn60E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dls = DataLoaders(dl, valid_dl)"
      ],
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQEWNTegbhHO",
        "colab_type": "text"
      },
      "source": [
        "Then we define our learner. It contains everything needed for our training loop:\n",
        "\n",
        "1.   DataLoaders containing our training and validation sets.\n",
        "2.   Model construction containing our neural network layers.\n",
        "3.   Optimization method.\n",
        "4.   Loss function.\n",
        "5.   Metric used for evaluation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qqRo0NxyoYdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(dls, nn.Linear(28*28,10), opt_func=SGD,\n",
        "                loss_func=loss_fn, metrics=accuracy)"
      ],
      "execution_count": 190,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HKDz8qfcgq7",
        "colab_type": "text"
      },
      "source": [
        "Now we can call fit and train our neural network for the specified amount of epochs using the selected learning rate."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZqhKC9HJoiLk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "37de2eba-c530-4bc8-a25c-0dcf27381cde"
      },
      "source": [
        "learn.fit(20, lr=lr)"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.246657</td>\n",
              "      <td>0.211038</td>\n",
              "      <td>0.948667</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.182390</td>\n",
              "      <td>0.174122</td>\n",
              "      <td>0.954083</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.161337</td>\n",
              "      <td>0.158016</td>\n",
              "      <td>0.957750</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.149650</td>\n",
              "      <td>0.148503</td>\n",
              "      <td>0.959500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.141770</td>\n",
              "      <td>0.142068</td>\n",
              "      <td>0.960167</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.135925</td>\n",
              "      <td>0.137359</td>\n",
              "      <td>0.961000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.131332</td>\n",
              "      <td>0.133732</td>\n",
              "      <td>0.961667</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.127578</td>\n",
              "      <td>0.130832</td>\n",
              "      <td>0.961917</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.124423</td>\n",
              "      <td>0.128451</td>\n",
              "      <td>0.962667</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.121715</td>\n",
              "      <td>0.126453</td>\n",
              "      <td>0.963083</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.119351</td>\n",
              "      <td>0.124749</td>\n",
              "      <td>0.963083</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.117259</td>\n",
              "      <td>0.123276</td>\n",
              "      <td>0.963667</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.115389</td>\n",
              "      <td>0.121989</td>\n",
              "      <td>0.964250</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.113701</td>\n",
              "      <td>0.120853</td>\n",
              "      <td>0.964667</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.112165</td>\n",
              "      <td>0.119842</td>\n",
              "      <td>0.964750</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.110758</td>\n",
              "      <td>0.118938</td>\n",
              "      <td>0.965167</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.109463</td>\n",
              "      <td>0.118124</td>\n",
              "      <td>0.965167</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.108264</td>\n",
              "      <td>0.117387</td>\n",
              "      <td>0.965583</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.107149</td>\n",
              "      <td>0.116718</td>\n",
              "      <td>0.966000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.106107</td>\n",
              "      <td>0.116107</td>\n",
              "      <td>0.966333</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ8eO8rup4f3",
        "colab_type": "text"
      },
      "source": [
        "#Adding a Nonlinearity"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkaSCzCFp60G",
        "colab_type": "text"
      },
      "source": [
        "So just now, we have created a very simple one layer linear model. Now we are going to convert it into the neural network, which contains two layers. To do that, we need to specify the relu layer in between two linear layers. Relu stands for a rectified linear unit. Also, known as... a very simple function with a fancy name? That relu does it simply takes all negative values and converts it to zero. We need to do this because we can not stack multiple linear layers, one on another directly. If we do that, it's no different from having another big linear layer with more parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CirqzMajlBjc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "16d330e0-551b-48dc-ff96-db7ae8061219"
      },
      "source": [
        "x = torch.linspace(-2,2)\n",
        "plt.plot(x,F.relu(x))"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7ff905d3bcc0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 192
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByROVqG1hSVU",
        "colab_type": "text"
      },
      "source": [
        "Let's create our new model structure. Before then, we had only one linear layer, our input and output size for one layer was ('784,10'). That was because we had 784 pixels as input and 10 classes as output. Now when we have two linear layers, we need to do it differently. The input size of the first layer will be the same as before ('784'), but the output will be different. That is because now we don't output the answer directly, but we output our one layer calculations, to be used as an input to the second layer ( after applying relu).\n",
        "So first layer output and second layer input have to be the same size(we are going to select 30). And the second layer output will be 10(just like the output of the model that we had before, which used a single layer). \n",
        "\n",
        "To create this kind of model with PyTorch is very easy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHPlYU_LBF22",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28,30),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(30,10)\n",
        ")"
      ],
      "execution_count": 205,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhDHC75ji9iM",
        "colab_type": "text"
      },
      "source": [
        "Lets again use learners with the same parameters as before. The only different thing is our model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYxcBPwWBF6W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = Learner(dls, simple_net, opt_func=SGD,\n",
        "                loss_func=loss_fn, metrics=accuracy)"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVk9CGYGCR7f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "65687d3d-ceb5-41dc-a252-a9bbf3814ce1"
      },
      "source": [
        "#hide_output\n",
        "learn.fit(20, 0.5)"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.189856</td>\n",
              "      <td>0.147509</td>\n",
              "      <td>0.958333</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.130752</td>\n",
              "      <td>0.122994</td>\n",
              "      <td>0.963833</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.112055</td>\n",
              "      <td>0.111091</td>\n",
              "      <td>0.967417</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.099534</td>\n",
              "      <td>0.102761</td>\n",
              "      <td>0.970000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.089759</td>\n",
              "      <td>0.096738</td>\n",
              "      <td>0.971500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.081751</td>\n",
              "      <td>0.092475</td>\n",
              "      <td>0.973000</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.075043</td>\n",
              "      <td>0.088797</td>\n",
              "      <td>0.974833</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.069271</td>\n",
              "      <td>0.085902</td>\n",
              "      <td>0.975667</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.064231</td>\n",
              "      <td>0.083595</td>\n",
              "      <td>0.976583</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.059664</td>\n",
              "      <td>0.081601</td>\n",
              "      <td>0.977250</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.055668</td>\n",
              "      <td>0.079715</td>\n",
              "      <td>0.977833</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.052135</td>\n",
              "      <td>0.078505</td>\n",
              "      <td>0.978250</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.048920</td>\n",
              "      <td>0.077386</td>\n",
              "      <td>0.978333</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.045912</td>\n",
              "      <td>0.076355</td>\n",
              "      <td>0.978500</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.043248</td>\n",
              "      <td>0.075571</td>\n",
              "      <td>0.978833</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.040717</td>\n",
              "      <td>0.074855</td>\n",
              "      <td>0.979167</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.038373</td>\n",
              "      <td>0.074128</td>\n",
              "      <td>0.978917</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.036223</td>\n",
              "      <td>0.073744</td>\n",
              "      <td>0.979250</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.034221</td>\n",
              "      <td>0.073306</td>\n",
              "      <td>0.979250</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.032410</td>\n",
              "      <td>0.072851</td>\n",
              "      <td>0.979417</td>\n",
              "      <td>00:01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lILwnsevCNTh",
        "colab_type": "text"
      },
      "source": [
        "As you can see the accuracy increased to 98%."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KDa-goW6CY__",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "3f131f15-3a20-4d67-b407-71b41fe7e64e"
      },
      "source": [
        "plt.plot(L(learn.recorder.values).itemgot(2));"
      ],
      "execution_count": 209,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIF66G_BjNRL",
        "colab_type": "text"
      },
      "source": [
        "Thats it. Thank you very for reading!!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4jUzJ5pJDkd6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        },
        "outputId": "2d1bd0b6-938f-4669-efcf-196641f61342"
      },
      "source": [
        "!jupyter_to_medium --pub-name=\"Logistic Regression with Kannada-MNIST\" --tags=\"python, data science, fastai\" \"Logistic Regression with Kannada-MNIST.ipynb\""
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/jupyter_to_medium\", line 5, in <module>\n",
            "    from jupyter_to_medium._command_line import main\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_to_medium/__init__.py\", line 1, in <module>\n",
            "    from ._publish_to_medium import publish\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_to_medium/_publish_to_medium.py\", line 10, in <module>\n",
            "    from ._preprocesors import MarkdownPreprocessor, NoExecuteDataFramePreprocessor\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_to_medium/_preprocesors.py\", line 102, in <module>\n",
            "    ss_creator = make_repr_png()\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_to_medium/_screenshot.py\", line 196, in make_repr_png\n",
            "    ss = Screenshot(max_rows, max_cols, ss_width, ss_height, resize, chrome_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_to_medium/_screenshot.py\", line 74, in __init__\n",
            "    self.chrome_path = get_chrome_path(chrome_path)\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/jupyter_to_medium/_screenshot.py\", line 51, in get_chrome_path\n",
            "    raise OSError(\"Chrome executable not able to be found on your machine\")\n",
            "OSError: Chrome executable not able to be found on your machine\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSNt2dzmEOvJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}